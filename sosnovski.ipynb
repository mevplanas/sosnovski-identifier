{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing deep learning \n",
    "from ultralytics import YOLO\n",
    "import torch \n",
    "\n",
    "# Other functionlaities \n",
    "import os \n",
    "import pandas as pd \n",
    "import pickle \n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "# Checking if cuda is available\n",
    "print(\"Cuda available: \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and standartizing the labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pickle.load(open('labels.pkl', 'rb'))\n",
    "\n",
    "# Getting all the image_name entries \n",
    "image_names = [x['image_name'] for x in labels]\n",
    "image_names = list(set(image_names))\n",
    "print(f\"Total number of images: {len(image_names)}\")\n",
    "\n",
    "# Iterating over the image names and saving the labels for the images\n",
    "# to .txt files in the labels dir \n",
    "for image_name in image_names:\n",
    "    # Getting the labels for the image \n",
    "    labels_for_image = [x for x in labels if x['image_name'] == image_name]\n",
    "    # Getting the label strings \n",
    "    label_polygons = [x['polygon'] for x in labels_for_image]\n",
    "    # Converting from arrays to lists\n",
    "    label_polygons = [x.tolist() for x in label_polygons]\n",
    "    # Defining the path to labels \n",
    "    image_name_coords = image_name.split('.')[0]\n",
    "    image_name_coords += '.txt'\n",
    "    label_path = os.path.join('labels', image_name_coords)\n",
    "    # Writing the labels to the label path \n",
    "    with open(label_path, 'w') as f:\n",
    "        # Converting to strings \n",
    "        label_polygons = [str(x) for x in label_polygons]\n",
    "        label_polygons = [x.replace('[', '').replace(']', '').replace(',', '') for x in label_polygons]\n",
    "\n",
    "        # Adding the 0 label to the beginning of each label\n",
    "        label_polygons = ['0 ' + x for x in label_polygons]\n",
    "\n",
    "        # Writing to the file\n",
    "        f.write('\\n'.join(label_polygons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataset for yolo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir('images')\n",
    "print(f\"Total number of images: {len(images)}\")\n",
    "\n",
    "# Defining the ML directory \n",
    "ml_dir = 'ml_data'\n",
    "\n",
    "# If the ml dir already exists, we will remove it\n",
    "if os.path.exists(ml_dir):\n",
    "    shutil.rmtree(ml_dir)\n",
    "\n",
    "# Defining the high level images and labels dirs \n",
    "images_dir = os.path.join(ml_dir, 'images')\n",
    "labels_dir = os.path.join(ml_dir, 'labels')\n",
    "\n",
    "# In both of the images and labels, we will create the train and val directories\n",
    "# and then move the images and labels to the respective directories\n",
    "images_train_dir = os.path.join(images_dir, 'train')\n",
    "images_test_dir = os.path.join(images_dir, 'val')\n",
    "labels_train_dir = os.path.join(labels_dir, 'train')\n",
    "labels_test_dir = os.path.join(labels_dir, 'val')\n",
    "\n",
    "# Creating the directories\n",
    "os.makedirs(images_train_dir, exist_ok=True)\n",
    "os.makedirs(images_test_dir, exist_ok=True)\n",
    "os.makedirs(labels_train_dir, exist_ok=True)\n",
    "os.makedirs(labels_test_dir, exist_ok=True)\n",
    "\n",
    "# Splitting the images into test and train\n",
    "train_images, test_images = train_test_split(images, test_size=0.2)\n",
    "print(f\"Number of train images: {len(train_images)}\")\n",
    "print(f\"Number of test images: {len(test_images)}\")\n",
    "\n",
    "# Copying the images and the labels\n",
    "for image in train_images:\n",
    "    shutil.copy(os.path.join('images', image), images_train_dir)\n",
    "    image_name_coords = image.split('.')[0]\n",
    "    image_name_coords += '.txt'\n",
    "    shutil.copy(os.path.join('labels', image_name_coords), labels_train_dir)\n",
    "\n",
    "for image in test_images:\n",
    "    shutil.copy(os.path.join('images', image), images_test_dir)\n",
    "    image_name_coords = image.split('.')[0]\n",
    "    image_name_coords += '.txt'\n",
    "    shutil.copy(os.path.join('labels', image_name_coords), labels_test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the YOLO model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8m-seg.pt')\n",
    "model.train(data='segment.yaml', epochs=40, batch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
